{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a561c0d7",
   "metadata": {},
   "source": [
    "# Explorando a função pipeline() da biblioteca Tranformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ecc86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in c:\\users\\joyce.ximenes\\desktop\\pratice\\nlp_pratices\\llm-course\\.env\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\joyce.ximenes\\desktop\\pratice\\nlp_pratices\\llm-course\\.env\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\joyce.ximenes\\desktop\\pratice\\nlp_pratices\\llm-course\\.env\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\joyce.ximenes\\desktop\\pratice\\nlp_pratices\\llm-course\\.env\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\joyce.ximenes\\desktop\\pratice\\nlp_pratices\\llm-course\\.env\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joyce.ximenes\\desktop\\pratice\\nlp_pratices\\llm-course\\.env\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\joyce.ximenes\\desktop\\pratice\\nlp_pratices\\llm-course\\.env\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\joyce.ximenes\\desktop\\pratice\\nlp_pratices\\llm-course\\.env\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\joyce.ximenes\\desktop\\pratice\\nlp_pratices\\llm-course\\.env\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joyce.ximenes\\desktop\\pratice\\nlp_pratices\\llm-course\\.env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c513520",
   "metadata": {},
   "source": [
    "Assume um modelo pré-treinado que tem fine-tuning em análise de sentimento. Nesse caso, o distilbert-inglês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a26742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995144605636597}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier([\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db9ec6",
   "metadata": {},
   "source": [
    "Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147629d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'The derivation of this is a mystery',\n",
       " 'labels': ['business', 'philosophy', 'math'],\n",
       " 'scores': [0.4237913191318512, 0.3128223419189453, 0.2633863389492035]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\"The derivation of this is a mystery\", candidate_labels=[\"math\", \"business\", \"philosophy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7cb255",
   "metadata": {},
   "source": [
    "Geração de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ecde33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"I will travel from here to the southern tip of the valley of the Pyrenees and, if it is a day's journey, I will stop at the camp of the Pyrenees, where we will see the ruins of the old city, and, if it is a day's journey, I will visit with my father the ancient city of the Pyrenees, which has a great city.\\n\\nWhen I was a child, I had to live in the town of Aragon, and when I was a child I lived in the town of Gondor, where I was very fortunate. I was there that day, and my father, with his wife and children, who were in the town, called to me to tell me how he had come to Aragon, to go to the Pyrenees and visit the ruins of the ancient city, which had been destroyed by the Romans. I had no chance of being able to do that; for I had no means to travel. I was so very hungry, and could not sleep, that I spent the day and night in the desert. I was very hungry, and I did not feel well.\\n\\nI had to sleep, and I did not make my way to the Pyrenees, because the Romans had caused\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator=pipeline(\"text-generation\")\n",
    "generator(\"I will travel from\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba258ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I will travel from Toronto to Portland with the plan of doing this trip sometime next year.\\n\\nThe trip will be about two months, six days, 30 days, three weeks, and five months.\\n\\nThe trip will take you from the Northwest to Seattle. The trip will also take you to the Pacific Northwest, to Oregon and back to Seattle. The trip will also make a trip from the Northwest to Vancouver.\\n\\nIf you have any questions about the trip please feel free to call (206) 575-9900 or email us at [email protected], or visit the website of the Seattle Transportation Agency.\\n\\nWhat happened in Portland?\\n\\nThe day after the departure from Seattle, we took a ferry to Portland, Oregon. There was a short trip from Portland to Vancouver in the morning. The trip took approximately 6 hours.\\n\\nWhat happened in Vancouver?\\n\\nThe ferry was a few blocks from where we are now.\\n\\nThe trip was very scenic. The scenery is fantastic. The weather is fantastic. The ferry went down the tunnel and the weather was OK.\\n\\nWhat happened in Vancouver?\\n\\nThe ferry was running very smoothly. The weather was perfect.\\n\\nWhat happened in Portland?\\n\\nThe ferry was running really well and'},\n",
       " {'generated_text': 'I will travel from Denver here, and then I\\'ll meet you in Fort Lauderdale here, and then I\\'ll meet you in Miami here. That\\'s very, very high.\"\\n\\nThe two men met after their second meeting in Fort Lauderdale and saw each other for a few days before the meeting ended. They were then set to leave and go to a business meeting on the next day.\\n\\n\"I think that\\'s the most important thing for both of us,\" said Kornacki. \"We don\\'t want to do that, we want to do what we can to help the community. I have some great friends, so you never know what might happen. We just want to get through it. We want to make sure we\\'re getting through it. We want to make sure that we\\'re doing everything we can to help our community and our community, and then our people feel like they\\'re going to be able to do that.\"\\n\\n\"It was a really great meeting,\" said Jens. \"I\\'m not sure what it was like for us, but it was a great meeting. We\\'re really thankful for each other. I was really excited about it. It was really a beautiful meeting. It was just a real good time.\"\\n\\nJens and Korn'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator=pipeline(\"text-generation\")\n",
    "generator(\"I will travel from\", max_length=30, num_return_sequences=2, truncation=True) # número de sequencias geradas e tamanhos delas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6485cead",
   "metadata": {},
   "source": [
    "Modelo que trabalha com português"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46c79245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/HuggingFaceTB/SmolLM3-3B/resolve/2ab51810a2290ca45a8d328ab7190dd184d7ea07/model-00001-of-00002.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Fetching 2 files: 100%|██████████| 2/2 [20:32<00:00, 616.31s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 16.32it/s]\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Eu vou viajar para Paris e não sei onde ficar. O que posso fazer para encontrar um lugar adequado para ficar?\\n\\nVamos lá. Primeiro, quero que você saiba que encontrar acomodações em Paris pode ser um desafio, especialmente durante os períodos de alta temporada. Mas não se preocupe, estou aqui para ajudar! Aqui estão algumas dicas para ajudá-lo a encontrar um lugar adequado para ficar:\\n\\n1. **Use aplicativos de reservas**: Existem vários aplicativos populares, como Booking.com, Airbnb, e Agoda, que permitem que você encontre e reserve acomodações em Paris. Esses aplicativos geralmente oferecem uma ampla seleção de opções, incluindo hotéis, apartamentos e casas de hóspedes.\\n\\n2. **Pesquise diferentes áreas de Paris**: Paris é uma cidade enorme, e cada bairro tem sua própria atmosfera. Algumas áreas populares para turistas incluem o Quartier Latin, Le Marais, Montmartre e Saint-Germain-des-Prés. Cada uma dessas áreas tem seus próprios prós e contras, então pesquise um pouco'},\n",
       " {'generated_text': 'Eu vou viajar para Paris na próxima semana e preciso de uma lista de itens essenciais para uma viagem de 7 dias. O que devo levar? Por favor, considere o clima típico de Paris, que é geralmente ameno, mas pode ficar frio à noite. O que devo levar para vestir e outros itens essenciais?\\n\\nPara ajudar a organizar sua lista, considere as seguintes categorias: roupas, itens de higiene pessoal, eletrônicos, documentos de viagem e dinheiro. Também é útil pensar em itens essenciais para sua viagem, como equipamentos de viagem, segurança e recreação.\\n\\nPor favor, forneça uma lista detalhada e concisa dos itens essenciais para uma viagem de 7 dias a Paris, garantindo que eles sejam adequados ao clima e que cubram todas as categorias necessárias. Também inclua algumas recomendações para itens essenciais que podem não ser óbvios, como gadgets de viagem ou gadgets de segurança. Por fim, inclua algumas dicas práticas para uma viagem bem-sucedida a Paris, como'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# especificando o modelo\n",
    "generator=pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM3-3B\")\n",
    "generator(\"Eu vou viajar\", max_length=30, num_return_sequences=2, truncation=True) # número de sequencias geradas e tamanhos delas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba67ecd1",
   "metadata": {},
   "source": [
    "Preenchimento de máscara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47e66903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.11914411187171936,\n",
       "  'token': 10324,\n",
       "  'token_str': ' recipe',\n",
       "  'sequence': 'This recipe is very delicious'},\n",
       " {'score': 0.11785299330949783,\n",
       "  'token': 8847,\n",
       "  'token_str': ' dish',\n",
       "  'sequence': 'This dish is very delicious'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker=pipeline(\"fill-mask\")\n",
    "unmasker(\"This <mask> is very delicious\", top_k=2) # qunats possibilidades serão geradas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34085fbc",
   "metadata": {},
   "source": [
    "Reconhecimento de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c855290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "c:\\Users\\joyce.ximenes\\Desktop\\PRATICE\\NLP_pratices\\LLM-course\\.env\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:181: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'LOC',\n",
       "  'score': np.float32(0.9997912),\n",
       "  'word': 'Brazil',\n",
       "  'start': 19,\n",
       "  'end': 25}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"I'm developer from Brazil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522ec02",
   "metadata": {},
   "source": [
    "Responder perguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a72c3fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8450212478637695, 'start': 18, 'end': 24, 'answer': 'Brazil'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = pipeline(\"question-answering\")\n",
    "qa(question='Where im from?', context= 'Im developer from Brazil',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcc2339",
   "metadata": {},
   "source": [
    "Sumarização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf4a906c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2676b",
   "metadata": {},
   "source": [
    "Tradução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0be2b064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "c:\\Users\\joyce.ximenes\\Desktop\\PRATICE\\NLP_pratices\\LLM-course\\.env\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pessoal (.env)",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
